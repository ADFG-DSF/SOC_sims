---
title: "SOC_sims"
author: "Adam Reimer"
format:
  html:
    embed-resources: true
editor: visual
---

```{r include = FALSE}
packs <- c("tidyverse", "ggforce", "RcppRoll", "knitr")
lapply(packs, require, character.only = TRUE)

# source functions
function_files <- list.files(path="..\\functions")
lapply(function_files, function(x) source(paste0("..\\functions\\", x)))

vec_lnalpha <- seq(1, 2, length.out = 3)
vec_sigW <- seq(0.25, 0.75, length.out = 3)
vec_phi <- seq(0, .7, length.out = 3)
beta <- 0.0001
df_power <- data.frame(lnalpha = vec_lnalpha,
                       power = c(0.6, 0.7, 0.8)) #how to pick these. High for SOC sims. Should be lower for OPY sims.
input <- 
  expand.grid(lnalpha = vec_lnalpha, sigW = vec_sigW, phi = vec_phi) %>%
  mutate(beta = beta, 
         Smsy = get_Smsy(lnalpha, beta, TRUE, sigma = sigW, phi = phi),
         lb_eggers = Smsy * 0.8, #Egger bounds
         ub_eggers = Smsy * 1.6) %>%
  rowwise() %>%
  mutate(lb_pctMSY = optimise(get_bounds, #'true' OYP bounds
                              1:Smsy, 
                              lnalpha = lnalpha, 
                              beta = beta,
                              pct_MSY = 0.9,
                              correct = TRUE,
                              sigma = sigW,
                              phi = phi)$minimum,
          ub_pctMSY = optimise(get_bounds, 
                              Smsy:(Smsy*5), 
                              lnalpha = lnalpha, 
                              beta = beta,
                              pct_MSY = 0.7,
                              correct = TRUE,
                              sigma = sigW,
                              phi = phi)$minimum) %>%
  ungroup() %>%
  left_join(df_power, by = "lnalpha")

Chinook_age <- c('3' = 0.1, '4' = 0.2, '5' = 0.3, '6' = 0.38, '7' = 0.02)

input_sims = 1000
```

### Simulated Run Sizes with Historical and Low Productivity

Two sets of simulations were run with 27 parameter combinations $\textrm{log}(\alpha) = (1.0, 1.5, 2.0)$, $\sigma = (0.25, 0.50, 0.75)$, and $\phi = (0.00, 0.35, 0.70)$. $\beta=0.0001$ and $p_a=(0.10, 0.20, 0.30, 0.38, 0.02)$ were for all simulations while lower bound of the escapement goal was the escapement that predicted a mean return which produced 90% of MSY while the upper bound was was the escapement that predicted a mean return which produced 70% of MSY. Power varied according to the productivity of the stock and was set to $0.6$, $0.7$, or $0.8$ when $\textrm{log}(\alpha)$ was set to $1.0$, $1.5$ and $2.0$ respectively. Management variability was set to 0.2 for both observation ($\sigma_N$) and implementation ($\sigma_F$) error. The first simulation was exactly as described above while the second simulation was identical except that it reflected a low productivity situation where $\textrm{log}(\alpha)^*=\frac{lb}{\beta}$.

```{r include = FALSE}
sim_base <- 
  mapply(FUN = simSR_goal,
         lnalpha = input$lnalpha,
         sigW = input$sigW,
         phi = input$phi,
         lb_goal = input$lb_pctMSY,
         ub_goal = input$ub_pctMSY,
         power = input$power,
         MoreArgs = list(beta = beta,
                         age0 = Chinook_age,
                         Sims0 = input_sims,
                         sigN = 0.2,
                         sigF = 0.2,
                         Hfun = H_goal),
         SIMPLIFY = FALSE) %>%
  do.call("rbind", .)

sim_Seq <- 
  mapply(FUN = simSR_goal,
         lnalpha = input$lb_pctMSY*beta,  #reduced ln_alpha
         sigW = input$sigW,
         phi = input$phi,
         lb_goal = input$lb_pctMSY,
         ub_goal = input$ub_pctMSY,
         MoreArgs = list(beta = beta,
                         age0 = Chinook_age,
                         Sims0 = input_sims,
                         sigN = 0.2,
                         sigF = 0.2,
                         Hfun = H_goal),
         SIMPLIFY = FALSE) %>%
  lapply(function(x) rename(x, lnalpha_red = lnalpha)) %>%
  do.call("rbind", .) %>%
  left_join(input[, c("lnalpha", "lb_pctMSY", "ub_pctMSY")], by = c("lb_goal" = "lb_pctMSY", "ub_goal" = "ub_pctMSY"))

# * Base Seq compare -----------------------------------------------
temp_base <- sim_base %>%
  mutate(scenario = "Historical")
temp_Seq <- sim_Seq %>%
  mutate(scenario = "Low") %>%
  select(-lnalpha_red)
baseSeq_combined <- 
  rbind(temp_base, temp_Seq) %>%
  group_by(lnalpha, sigW, phi, scenario) %>%
  select(-F, -U, -N) %>% 
  mutate(change = case_when(SOC != lag(SOC) ~ TRUE, TRUE ~ FALSE),
         n_change = cumsum(change),
         deviation_lb = (S - lb_goal) / lb_goal) %>%
  group_by(lnalpha, sigW, phi, scenario, n_change, SOC) %>%
  summarise(length = length(n_change),
            deviation_lb = mean(deviation_lb),
            miss = sum((S < lb_goal)) / length,
            mean_S = mean(S))

baseSeq_pct_SOC <- list()
for(i in 1:length(unique(input$lnalpha))){
  baseSeq_pct_SOC[[i]] <-
    baseSeq_combined %>% 
    group_by(lnalpha, sigW, phi, scenario, SOC) %>% 
    summarize(pct_SOC = sum(length)/input_sims) %>% 
    ggplot(aes(x = scenario, y  = pct_SOC, fill = SOC)) + 
    geom_bar(stat = "identity") +
    theme_bw() +
    facet_grid_paginate(paste0("\u03C6: ", phi) ~ paste0("ln(\u03B1): ", lnalpha) + paste0("\u03C3: ", sigW), 
                        ncol = 3, nrow = 3, page = i)
}
```

### SOC Designations with Historical and Low Productivity {#sec-soc-designations}

Having seen a time series of run sizes and escapemtns under each productivity regime lets take a look at the freqency of SOC designations under each regime (@fig-baseSeq). The results are generally similar to what most of us might predict... SOC designations are rare under historical productivity regimes and become the expectation under low productivity regimes. One way to interpret these results might be to consider them in light of a hypothesis test where $H_0= \textrm{stock productivity is at it's historic average}$. In that light the risk of a false negative (declaring a stock as a stock of concern when productivity is near it's historic average) is negligible while the power of the test (ability to detect low productivity when it occurs is \~$50$% or less. If this interpretation is deemed valid it suggests that recommending a SOC definition when the criteria has been satisfied in 4 of the last 5 years and recommending desisting when the criteria has not been met in 4 of the last 5 years is a weak indicator of an extreme reduction in stock productivity.

My observation would be that ADF&G staff are in general reluctant to make SOC recomendations and these results suggest we might consider being less so. While this technique suggests a mechanism to test other interpretations of *chronic inability* (x of y years, y consecutive years, rolling mean escapement) as perhaps more powerful indicators of low contemporary productivity I though it was best to postpone that work untill staff have an opportunity to weigh in.

```{r echo = FALSE, warning = FALSE}
#| label: fig-baseSeq
#| fig.height: 8
#| fig.width: 8
#| fig.cap: "Percent of simulated runs under each stock of concern designation for 27 possible stock recruit parameter combinations and 2 productivity regimes."
#| layout-nrow: 3
#| fig-subcap: 
#|   - "Historical productivity: log(\u03B1) = 1.0"
#|   - "Historical productivity: log(\u03B1) = 1.5"
#|   - "Historical productivity: log(\u03B1) = 2.0"
baseSeq_pct_SOC[[1]]
baseSeq_pct_SOC[[2]]
baseSeq_pct_SOC[[3]]
```

### Rebuilding

After a stock of concern is declared what can we do about it?
